{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "482f2c53-f47b-40a9-97ae-bda84c4823ff",
   "metadata": {},
   "source": [
    "Acknowledgement: Material based on CS224U course by Prof Potts\n",
    "Youtube lectures: https://tinyurl.com/course-cs234u\n",
    "github: https://github.com/cgpotts/cs224u/\n",
    "\n",
    "This Notebook available at: https://github.com/ljohri/NLP-RAG-Concepts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0517018a-8424-4d16-ae20-903467cbff40",
   "metadata": {},
   "source": [
    "### Concepts\n",
    "src: https://tinyurl.com/rag-notes\n",
    "\n",
    "\n",
    "<img src=\"RAG Architecture Explaination.png\" alt=\"Page1\" width=\"900\">\n",
    "<img src=\"RAG Architecture Explaination 2.png\" alt=\"Page1\" width=\"900\">\n",
    "<img src=\"RAG Architecture Explaination 3.png\" alt=\"Page1\" width=\"900\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31952df4-2615-4e3f-81db-29188fdf1940",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "917f189c-8045-4732-ac28-2964b334b31c",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9fad03a-ed49-4f18-9c7b-e617b8053d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # This library is our indicator that the required installs\n",
    "    # need to be done.\n",
    "    import datasets\n",
    "except ModuleNotFoundError:\n",
    "    !git clone https://github.com/cgpotts/cs224u/\n",
    "    !pip install -r cs224u/requirements.txt\n",
    "    import sys\n",
    "    sys.path.append(\"cs224u\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b800db-f1d4-49be-b729-e64d9fcf0908",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dc8d963b-a91b-4f44-bca6-c335a52ffdec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import os\n",
    "import dspy\n",
    "import warnings\n",
    "from openai import OpenAI\n",
    "import random\n",
    "from dspy.teleprompt import LabeledFewShot\n",
    "from dotenv import load_dotenv\n",
    "from dspy.evaluate import answer_exact_match\n",
    "from dspy.evaluate.evaluate import Evaluate\n",
    "\n",
    "root_path = 'dspy'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a94ba0-38fe-4bdd-b672-589a6c797ce8",
   "metadata": {},
   "source": [
    "## Load the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2e2f1feb-54bd-4330-8817-079ae0e74a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"DSP_NOTEBOOK_CACHEDIR\"] = os.path.join(root_path, 'cache')\n",
    "# keep the API keys in a `.env` file in the local root directory\n",
    "load_dotenv()\n",
    "openai_key = os.getenv('OPENAI_API_KEY')  # use the .env file as it is a good practice to keep keys outside of one's code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdb63cd-cece-4316-99d2-cd0e9d9a8ce2",
   "metadata": {},
   "source": [
    "## Download Colbertv2 Pretrained Patrameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "09a1fbb3-02f6-45e1-80d1-82ca3b7de4ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(os.path.join(\"data\", \"openqa\", \"colbertv2.0.tar.gz\")):\n",
    "    !mkdir -p data/openqa\n",
    "    # ColBERTv2 checkpoint trained on MS MARCO Passage Ranking (388MB compressed)\n",
    "    !wget https://downloads.cs.stanford.edu/nlp/data/colbert/colbertv2/colbertv2.0.tar.gz -P data/openqa/\n",
    "    !tar -xvzf data/openqa/colbertv2.0.tar.gz -C data/openqa/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b44371c-a64c-4869-b328-6f252e17e2ea",
   "metadata": {},
   "source": [
    "## Download Prebuilt ColBERT index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "956ce81a-4721-43d4-82e2-51ff41744caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_home = os.path.join(\"experiments\", \"notebook\", \"indexes\", \"cs224u.collection.2bits\")\n",
    "if not os.path.exists(index_home):\n",
    "    !wget https://web.stanford.edu/class/cs224u/data/cs224u.collection.2bits.tgz -P experiments/notebook/indexes\n",
    "    !tar -xvzf experiments/notebook/indexes/cs224u.collection.2bits.tgz -C experiments/notebook/indexes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b22df9-c669-421b-bfba-f719beb49de5",
   "metadata": {},
   "source": [
    "## Run the colbert server\n",
    "conda activate nlu\n",
    "\n",
    "git clone https://github.com/stanford-futuredata/ColBERT/ \n",
    "\n",
    "export INDEX_ROOT=experiments/notebook/indexes/cs224u.collection.2bits/ \n",
    "\n",
    "export INDEX_HOME=cs224u.collection.2bits \n",
    "\n",
    "export PORT=8888 \n",
    "\n",
    "python ColBERT/server.py \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e17c786-5838-416d-bd2d-c1e6ff0d4ed7",
   "metadata": {},
   "source": [
    "## Get the handle to the RAG Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57fa9f57-6fce-4dfc-af3d-d74210d34901",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the handle to the RAG model\n",
    "rm = dspy.ColBERTv2(url=\"http://127.0.0.1:8888/api/search\")\n",
    "\n",
    "#get the handle for LLM\n",
    "lm = dspy.OpenAI(model='gpt-3.5-turbo', api_key=openai_key)\n",
    "\n",
    "dspy.settings.configure(lm=lm, rm=rm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "303d27b7-1833-445d-a117-742aee0d7478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncPage[Model](data=[Model(id='gpt-4o-audio-preview-2024-12-17', created=1734034239, object='model', owned_by='system'), Model(id='dall-e-3', created=1698785189, object='model', owned_by='system'), Model(id='dall-e-2', created=1698798177, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview-2024-10-01', created=1727389042, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview-2024-10-01', created=1727131766, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview', created=1727659998, object='model', owned_by='system'), Model(id='babbage-002', created=1692634615, object='model', owned_by='system'), Model(id='tts-1-hd-1106', created=1699053533, object='model', owned_by='system'), Model(id='text-embedding-3-large', created=1705953180, object='model', owned_by='system'), Model(id='gpt-4', created=1687882411, object='model', owned_by='openai'), Model(id='text-embedding-ada-002', created=1671217299, object='model', owned_by='openai-internal'), Model(id='tts-1-hd', created=1699046015, object='model', owned_by='system'), Model(id='gpt-4o-mini-audio-preview', created=1734387424, object='model', owned_by='system'), Model(id='gpt-4-0125-preview', created=1706037612, object='model', owned_by='system'), Model(id='gpt-4o-audio-preview', created=1727460443, object='model', owned_by='system'), Model(id='o3-mini', created=1737146383, object='model', owned_by='system'), Model(id='gpt-4-turbo-preview', created=1706037777, object='model', owned_by='system'), Model(id='o1-preview-2024-09-12', created=1725648865, object='model', owned_by='system'), Model(id='o3-mini-2025-01-31', created=1738010200, object='model', owned_by='system'), Model(id='gpt-4o-mini-realtime-preview', created=1734387380, object='model', owned_by='system'), Model(id='gpt-4o-mini-realtime-preview-2024-12-17', created=1734112601, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct-0914', created=1694122472, object='model', owned_by='system'), Model(id='gpt-4o-mini-search-preview', created=1741391161, object='model', owned_by='system'), Model(id='tts-1-1106', created=1699053241, object='model', owned_by='system'), Model(id='o1-pro-2025-03-19', created=1742251504, object='model', owned_by='system'), Model(id='davinci-002', created=1692634301, object='model', owned_by='system'), Model(id='o1-2024-12-17', created=1734326976, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-1106', created=1698959748, object='model', owned_by='system'), Model(id='o1', created=1734375816, object='model', owned_by='system'), Model(id='o1-pro', created=1742251791, object='model', owned_by='system'), Model(id='gpt-4-turbo', created=1712361441, object='model', owned_by='system'), Model(id='gpt-4o-realtime-preview-2024-12-17', created=1733945430, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-instruct', created=1692901427, object='model', owned_by='system'), Model(id='gpt-3.5-turbo', created=1677610602, object='model', owned_by='openai'), Model(id='chatgpt-4o-latest', created=1723515131, object='model', owned_by='system'), Model(id='gpt-4o-mini-search-preview-2025-03-11', created=1741390858, object='model', owned_by='system'), Model(id='gpt-4o-2024-11-20', created=1739331543, object='model', owned_by='system'), Model(id='whisper-1', created=1677532384, object='model', owned_by='openai-internal'), Model(id='gpt-4o-2024-05-13', created=1715368132, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-16k', created=1683758102, object='model', owned_by='openai-internal'), Model(id='gpt-4-turbo-2024-04-09', created=1712601677, object='model', owned_by='system'), Model(id='gpt-4-1106-preview', created=1698957206, object='model', owned_by='system'), Model(id='o1-preview', created=1725648897, object='model', owned_by='system'), Model(id='gpt-4-0613', created=1686588896, object='model', owned_by='openai'), Model(id='gpt-4o-search-preview', created=1741388720, object='model', owned_by='system'), Model(id='gpt-4.5-preview', created=1740623059, object='model', owned_by='system'), Model(id='gpt-4.5-preview-2025-02-27', created=1740623304, object='model', owned_by='system'), Model(id='gpt-4o-search-preview-2025-03-11', created=1741388170, object='model', owned_by='system'), Model(id='tts-1', created=1681940951, object='model', owned_by='openai-internal'), Model(id='omni-moderation-2024-09-26', created=1732734466, object='model', owned_by='system'), Model(id='text-embedding-3-small', created=1705948997, object='model', owned_by='system'), Model(id='gpt-4o-mini-tts', created=1742403959, object='model', owned_by='system'), Model(id='gpt-4o', created=1715367049, object='model', owned_by='system'), Model(id='gpt-4o-mini', created=1721172741, object='model', owned_by='system'), Model(id='gpt-4o-2024-08-06', created=1722814719, object='model', owned_by='system'), Model(id='gpt-4o-transcribe', created=1742068463, object='model', owned_by='system'), Model(id='gpt-4o-mini-2024-07-18', created=1721172717, object='model', owned_by='system'), Model(id='gpt-4o-mini-transcribe', created=1742068596, object='model', owned_by='system'), Model(id='o1-mini', created=1725649008, object='model', owned_by='system'), Model(id='gpt-4o-mini-audio-preview-2024-12-17', created=1734115920, object='model', owned_by='system'), Model(id='gpt-3.5-turbo-0125', created=1706048358, object='model', owned_by='system'), Model(id='o1-mini-2024-09-12', created=1725648979, object='model', owned_by='system'), Model(id='omni-moderation-latest', created=1731689265, object='model', owned_by='system')], object='list')\n"
     ]
    }
   ],
   "source": [
    "client = OpenAI(api_key = openai_key)\n",
    "models = client.models.list()\n",
    "print(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23f142c1-fdcf-44b5-99db-83956438dd74",
   "metadata": {},
   "source": [
    "## SQuAD is the dataset with question-answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03c5d507-0957-4abc-9600-239f522c312c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96dfc731ae10455984705a7931bb8a32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/7.62k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea9c963b85a24611a8484ddf36aebf3c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train-00000-of-00001.parquet:   0%|          | 0.00/14.5M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bd3734abb81448fb1adf1944331892b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "validation-00000-of-00001.parquet:   0%|          | 0.00/1.82M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1eb49be01f424dd488666e0771ad214c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split:   0%|          | 0/87599 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f1de28c3a7d4f699efd6c5a93323a57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating validation split:   0%|          | 0/10570 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_squad_split(squad, split=\"validation\"):\n",
    "    \"\"\"\n",
    "    Use `split='train'` for the train split.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    list of dspy.Example with attributes question, answer\n",
    "\n",
    "    \"\"\"\n",
    "    data = zip(*[squad[split][field] for field in squad[split].features])\n",
    "    exs = [dspy.Example(question=q, answer=a['text'][0]).with_inputs(\"question\")\n",
    "           for eid, title, context, q, a in data]\n",
    "    return exs\n",
    "    \n",
    "squad = load_dataset(\"squad\", trust_remote_code=True)\n",
    "squad_train = get_squad_split(squad, split=\"train\")\n",
    "squad_train = get_squad_split(squad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fde141-388e-47e0-b28a-36d0e98f1e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(1)\n",
    "\n",
    "dev_exs = random.sample(squad_dev, k=200) #reducing the size of the for development purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c69815-2999-4f3e-b710-9c5d36a63348",
   "metadata": {},
   "source": [
    "## DSPy Basics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b66e476-8682-4ad8-97f0-f97e24e059db",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm(\"What is the birthplace of the first author to win a Hugo Award for a translation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2649804-f1d5-498c-804f-d3e817ab7c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lm(\"Which U.S. states border no U.S. states?\", temperature=0.9, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990021b6-94a8-43c3-ab43-942ccbfea07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = lm.inspect_history(n=1)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814229b8-1718-409b-b302-4c04e061e82b",
   "metadata": {},
   "source": [
    "## Signature-based prediction\n",
    "In DSPy, signatures are declarative statements about what we want the model to do. In the following \"question -> answer\" is the signature (the most basic QA signature one could write), and dspy.Predict is used to turn this into a complete QA system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cd8014-09dd-45a4-a309-b8f56cb0c959",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_predictor = dspy.Predict(\"question -> answer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303d0d35-bf14-42a6-bec6-4e38f0e49418",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_predictor(question=\"What is the birthplace of the first author to win a Hugo Award for a translation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eab475-c1bb-4df7-bf0b-f875e934e8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#what is seen by the LLM Model\n",
    "_ = lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa54552-ea29-469c-8350-ec82a1f92de4",
   "metadata": {},
   "source": [
    "In many cases, we will want more control over the prompt. Writing a small custom dspy.Signature class is the easiest way to accomplish this. In the following, we just just tweak the initial instruction and provide some formatting guidance for the answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b46248-1b4e-4bed-bdf7-0fe95765b21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicQASignature(dspy.Signature):\n",
    "    __doc__ = \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f7db68a-b0ca-405c-abff-46a70944313a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_predictor = dspy.Predict(BasicQASignature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8604de42-d77d-423f-9623-c9855fe3f98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sig_predictor(question=\"Which U.S. states border no U.S. states?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84452502-6e2a-473e-91b2-22138e4d8550",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b61fbf07-c3a7-40f4-90b6-e8bd9f288b84",
   "metadata": {},
   "source": [
    "## Modules\n",
    "One of the hallmarks of DSPy is that it adopts design patterns from PyTorch. The main example of this is DSPy's use of the Module as the basic unit for writing simple and complex programs. Here is a very basic module for QA that makes use of BasicQASignature as we defined it just above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4593dab-eea8-45c6-90e4-48429ce35d20",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicQA(dspy.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.generate_answer = dspy.Predict(BasicQASignature)\n",
    "\n",
    "    def forward(self, question):\n",
    "        return self.generate_answer(question=question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "227f8e84-7522-423c-96e2-9cd74742a2d5",
   "metadata": {},
   "source": [
    "As with PyTorch, the forward method is called when we want to make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c93a52df-5ef9-4a1a-8e08-c383c8d38d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_qa_model = BasicQA()\n",
    "basic_qa_model(question=\"What is the birthplace of the first author to win a Hugo Award for a translation?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "701511ed-2538-41c6-b717-1e5505c16eb9",
   "metadata": {},
   "source": [
    "The modular design of DSPy starts to become apparent now. If you want to change the above to use chain of thought instead of regular predictions, you need only change dspy.Predict to dspy.ChainOfThought, and similarly for dspy.ReAct, dspy.ProgramOfThought, or a module you wrote yourself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8c6ee3-49c9-4f01-aa13-5bc8f8a9a780",
   "metadata": {},
   "outputs": [],
   "source": [
    "fewshot_teleprompter = LabeledFewShot(k=3) ##And then we call compile on basic_qa_model as we defined it above. This returns a new module that we use like any other in DSPy:\n",
    "print(squad_train[:3])\n",
    "basic_fewshot_qa_model = fewshot_teleprompter.compile(basic_qa_model, trainset=squad_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b5c590-97c2-4ef4-844c-50c39ade6913",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_fewshot_qa_model(question=\"What is the birthplace of the first author to win a Hugo Award for a translation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a223319-d2d8-4bf2-b723-24f3b75276ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = lm.inspect_history(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6942b3-aca8-4554-9064-d511ad4c6613",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b22a6545-3531-4c98-b5bf-108fe167ae09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer_exact_match(dspy.Example(answer=\"STAGE 2!\"), dspy.Prediction(answer=\"stage 2\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf6939a-4b93-4fc3-a634-886482bf6871",
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_evaluater = Evaluate(\n",
    "    devset=dev_exs[: 15],\n",
    "    num_threads=1,\n",
    "    display_progress=True,\n",
    "    display_table=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e73cc2-eb81-47ac-a026-9c63149e1547",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d667ac-2648-4df4-a10d-b12062d66639",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = dspy.Retrieve(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a2632e-128f-4ea4-8805-968c5be8cd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "passages = retriever(\"What is the birthplace of the first author to win a Hugo Award for a translation?\")\n",
    "passages.passages[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8f68481-8540-4f6a-be34-1c2cd617345c",
   "metadata": {},
   "source": [
    "### Finally, putting the system together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef8074b-dc0c-4c5a-b543-8b5c69832c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ContextQASignature(dspy.Signature):\n",
    "    __doc__ = \"\"\"Answer questions with short factoid answers.\"\"\"\n",
    "\n",
    "    context = dspy.InputField(desc=\"may contain relevant facts\")\n",
    "    question = dspy.InputField()\n",
    "    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n",
    "    \n",
    "class RAG(dspy.Module):\n",
    "    def __init__(self, num_passages=1):\n",
    "        super().__init__()\n",
    "        self.retrieve = dspy.Retrieve(k=num_passages)\n",
    "        self.generate_answer = dspy.Predict(ContextQASignature)\n",
    "\n",
    "    def forward(self, question):\n",
    "        context = self.retrieve(question).passages\n",
    "        prediction = self.generate_answer(context=context, question=question)\n",
    "        return dspy.Prediction(context=context, answer=prediction.answer)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80c6cc8-01e1-40ec-824a-79b16f5be712",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_model = RAG(num_passages=3)\n",
    "rag_model(question=\"What is the birthplace of the first author to win a Hugo Award for a translation?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fe750b-43c7-450f-acfd-8517efde9d55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
